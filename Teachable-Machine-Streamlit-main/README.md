# ğŸ¤– Teachable Machine Streamlit

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)](https://streamlit.io/)
[![TensorFlow](https://img.shields.io/badge/tensorflow-2.13+-orange.svg)](https://tensorflow.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Une application Streamlit complÃ¨te et modulaire pour crÃ©er, entraÃ®ner, Ã©valuer et dÃ©ployer des modÃ¨les de classification et de rÃ©gression d'images, inspirÃ©e de Teachable Machine de Google mais avec plus de contrÃ´le et de fonctionnalitÃ©s avancÃ©es.

## ğŸš€ DÃ©mo en ligne

Vous pouvez essayer l'application directement : [ğŸ”— **Lancer la dÃ©mo**](https://teachable-machine-streamlit.streamlit.app) *(lien Ã  ajouter aprÃ¨s dÃ©ploiement)*

## âœ¨ FonctionnalitÃ©s principales

### ğŸ“ Gestion des donnÃ©es
- Import de dossiers d'images organisÃ©s par classes
- Support des archives ZIP
- Datasets de rÃ©gression via CSV
- Labelling et organisation automatique
- Split automatique train/validation/test (stratifiÃ©)
- Validation et statistiques des donnÃ©es

### ğŸ§ª EntraÃ®nement
- **ModÃ¨les prÃ©-entraÃ®nÃ©s** : MobileNetV3, EfficientNet, ResNet50
- **Transfer learning** optimisÃ© avec fine-tuning configurable
- **Augmentation de donnÃ©es** : rotation, flip, luminositÃ©, zoom, mixup/cutmix
- **Optimiseurs** : Adam, SGD, RMSprop avec schedulers
- **Callbacks** : Early stopping, rÃ©duction LR, sauvegarde automatique
- **Suivi en temps rÃ©el** : mÃ©triques et courbes d'apprentissage
- **Presets** : configurations rapide/Ã©quilibrÃ©/prÃ©cis

### ğŸ“Š Ã‰valuation et explicabilitÃ©
- **Classification** : Accuracy, Precision, Recall, F1, ROC/AUC, matrice de confusion
- **RÃ©gression** : MAE, MSE, RMSE, RÂ², MAPE, graphiques rÃ©siduels
- **ExplicabilitÃ©** : Grad-CAM et Score-CAM (en cours d'implÃ©mentation)
- **Comparaison de modÃ¨les** et recommandations
- **Export des rÃ©sultats** en CSV/PDF/HTML

### ğŸš€ DÃ©ploiement
- **InfÃ©rence temps rÃ©el** : upload, webcam, batch, URL
- **Export multi-format** : Keras, ONNX, TensorFlow Lite
- **GÃ©nÃ©ration d'API** FastAPI automatique
- **Guide de dÃ©ploiement** : local, cloud, mobile

### âš™ï¸ Configuration avancÃ©e
- Configuration centralisÃ©e via YAML
- Interface graphique pour tous les paramÃ¨tres
- SystÃ¨me de presets et sauvegarde
- Cache intelligent et gestion des logs
- Support multilingue (FR/EN)

## ğŸš€ Installation et dÃ©marrage rapide

### PrÃ©requis
- Python 3.10 ou supÃ©rieur
- 4GB RAM minimum (8GB recommandÃ©)
- GPU optionnel mais recommandÃ© pour l'entraÃ®nement

### Installation

1. **Cloner le repository**
```bash
git clone https://github.com/your-repo/teachable-machine-streamlit.git
cd teachable-machine-streamlit
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\\Scripts\\activate  # Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Lancer l'application**
```bash
streamlit run app.py
```

L'application sera accessible sur `http://localhost:8501`

### DÃ©marrage avec Make
```bash
make setup    # Installation des dÃ©pendances
make run      # Lancement de l'application
make demo     # DÃ©marrage avec donnÃ©es d'exemple
```

## ğŸ“– Guide d'utilisation

### 1. Classification d'images

1. **ğŸ“ DonnÃ©es** : 
   - Organisez vos images en dossiers par classe :
   ```
   mon_dataset/
   â”œâ”€â”€ chats/
   â”‚   â”œâ”€â”€ chat1.jpg
   â”‚   â””â”€â”€ chat2.jpg
   â””â”€â”€ chiens/
       â”œâ”€â”€ chien1.jpg
       â””â”€â”€ chien2.jpg
   ```
   - Ou utilisez les donnÃ©es d'exemple intÃ©grÃ©es

2. **ğŸ§ª EntraÃ®nement** :
   - Choisissez un modÃ¨le (MobileNetV3 recommandÃ© pour dÃ©buter)
   - SÃ©lectionnez un preset "Rapide" pour tester
   - Lancez l'entraÃ®nement et observez les mÃ©triques en temps rÃ©el

3. **ğŸ“Š Ã‰valuation** :
   - Analysez les mÃ©triques de performance
   - Examinez la matrice de confusion
   - Visualisez les explications Grad-CAM

4. **ğŸš€ DÃ©ploiement** :
   - Testez sur de nouvelles images
   - Exportez le modÃ¨le au format souhaitÃ©
   - GÃ©nÃ©rez une API REST automatiquement

### 2. RÃ©gression d'images

1. **ğŸ“ DonnÃ©es** :
   - PrÃ©parez un CSV avec chemins d'images et valeurs cibles :
   ```csv
   image_path,target
   images/img1.jpg,23.5
   images/img2.jpg,45.2
   ```

2. **ğŸ§ª EntraÃ®nement** :
   - Le type "rÃ©gression" sera dÃ©tectÃ© automatiquement
   - Configurez selon vos besoins (MSE, MAE...)

3. **ğŸ“Š Ã‰valuation** :
   - Analysez RÂ², RMSE, graphiques de rÃ©sidus
   - VÃ©rifiez la distribution des erreurs

### 3. Utilisation des donnÃ©es d'exemple

Pour tester rapidement l'application :

1. Cliquez sur "ğŸ® Charger la dÃ©mo" sur la page d'accueil
2. Ou utilisez les boutons de crÃ©ation de datasets synthÃ©tiques
3. Les donnÃ©es d'exemple incluent :
   - Classification : 3 classes avec images synthÃ©tiques colorÃ©es
   - RÃ©gression : images avec luminositÃ© corrÃ©lÃ©e Ã  la valeur cible

## ğŸ—ï¸ Architecture

### Structure du projet
```
teachable_machine_streamlit/
â”œâ”€â”€ app.py                          # Application principale
â”œâ”€â”€ pages/                          # Pages Streamlit
â”‚   â”œâ”€â”€ 1_ğŸ“_Data_&_Labelling.py   # Gestion des donnÃ©es
â”‚   â”œâ”€â”€ 2_ğŸ§ª_Experiment_&_Train.py # EntraÃ®nement
â”‚   â”œâ”€â”€ 3_ğŸ“Š_Evaluate_&_Explain.py # Ã‰valuation
â”‚   â”œâ”€â”€ 4_ğŸš€_Deploy_&_Realtime.py  # DÃ©ploiement
â”‚   â””â”€â”€ 5_âš™ï¸_Settings_&_Logs.py    # Configuration
â”œâ”€â”€ src/                            # Code source modulaire
â”‚   â”œâ”€â”€ data/                       # Chargement et transformation
â”‚   â”œâ”€â”€ models/                     # Architectures et heads
â”‚   â”œâ”€â”€ training/                   # Boucles d'entraÃ®nement
â”‚   â”œâ”€â”€ evaluation/                 # MÃ©triques et explicabilitÃ©
â”‚   â”œâ”€â”€ serving/                    # InfÃ©rence et export
â”‚   â”œâ”€â”€ utils/                      # Configuration, cache, logs
â”‚   â””â”€â”€ schemas/                    # Types et validation
â”œâ”€â”€ artifacts/                      # ModÃ¨les et rÃ©sultats sauvegardÃ©s
â”œâ”€â”€ samples/                        # DonnÃ©es d'exemple
â”œâ”€â”€ tests/                          # Tests unitaires
â”œâ”€â”€ config.yaml                     # Configuration par dÃ©faut
â””â”€â”€ requirements.txt                # DÃ©pendances
```

### Modules principaux

- **src.data** : Chargement, validation et transformation des donnÃ©es
- **src.models** : Registre des modÃ¨les, transfer learning, tÃªtes de classification/rÃ©gression
- **src.training** : EntraÃ®nement avec callbacks, schedulers, et optimiseurs
- **src.evaluation** : MÃ©triques, rapports, et explicabilitÃ©
- **src.serving** : InfÃ©rence, export multi-format, gÃ©nÃ©ration d'API
- **src.utils** : Configuration, cache, logs, et utilitaires

## ğŸ”§ Configuration

### Configuration via l'interface

Utilisez la page "âš™ï¸ Configuration" pour :
- Modifier les paramÃ¨tres via interface graphique
- Ã‰diter directement le YAML
- Appliquer des presets prÃ©dÃ©finis
- Exporter/importer des configurations

### Configuration manuelle

Ã‰ditez `config.yaml` pour personnaliser :

```yaml
# Exemple de configuration personnalisÃ©e
data:
  image_size: [224, 224]
  batch_size: 32
  validation_split: 0.2

training:
  epochs: 50
  learning_rate: 0.001
  optimizer: "adam"

model:
  backbone: "MobileNetV3Small"
  pretrained: true
  trainable_layers: 20

augmentation:
  enabled: true
  horizontal_flip: true
  rotation_range: 15
  brightness_range: [0.9, 1.1]
```

## ğŸš€ DÃ©ploiement

### Local avec FastAPI

1. EntraÃ®nez votre modÃ¨le dans l'application
2. Allez dans "ğŸš€ DÃ©ploiement" > "GÃ©nÃ©ration d'API"
3. Configurez et gÃ©nÃ©rez l'API
4. Lancez avec :
```bash
python serve_api.py
```

### Docker

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### Cloud (Heroku, AWS, GCP)

1. Utilisez le `Dockerfile` fourni
2. Configurez les variables d'environnement
3. DÃ©ployez via votre plateforme prÃ©fÃ©rÃ©e

## ğŸ§ª Tests

ExÃ©cutez les tests unitaires :

```bash
# Tests complets
make test

# Tests avec couverture
make test-cov

# Test d'un module spÃ©cifique
pytest tests/test_loaders.py -v
```

### Tests inclus

- **test_loaders.py** : Chargement et validation des donnÃ©es
- **test_trainer.py** : EntraÃ®nement sur donnÃ©es synthÃ©tiques
- **test_inference.py** : PrÃ©dictions et formats de sortie

## ğŸ“Š MÃ©triques et monitoring

### Logs structurÃ©s

Les logs sont sauvegardÃ©s en JSON dans `logs/` avec :
- Timestamp, niveau, module
- Ã‰vÃ©nements d'entraÃ®nement trackÃ©s
- MÃ©triques et erreurs contextuelles

### Cache intelligent

- Cache automatique des datasets et images prÃ©processÃ©es
- Optimisation des performances avec `tf.data`
- Gestion intelligente de la mÃ©moire

### Artefacts

Chaque entraÃ®nement sauvegarde dans `artifacts/run_YYYYMMDD_HHMMSS/` :
- ModÃ¨le final (`.keras`, `.h5`)
- Configuration complÃ¨te
- Historique d'entraÃ®nement
- MÃ©triques et graphiques
- Logs dÃ©taillÃ©s

## ğŸ¤ Contribution

### DÃ©veloppement

1. Forkez le repository
2. CrÃ©ez une branche feature : `git checkout -b feature/ma-nouvelle-fonctionnalite`
3. Installez les dÃ©pendances de dÃ©veloppement : `make setup-dev`
4. Respectez le style de code : `make lint`
5. Ajoutez des tests : `make test`
6. Soumettez une Pull Request

### Standards de code

- **Black** pour le formatage
- **Flake8** pour la qualitÃ©
- **MyPy** pour le typage
- **Pytest** pour les tests
- Documentation des fonctions publiques

## ğŸ“ Roadmap

### Version 1.1
- [ ] Grad-CAM et Score-CAM complets
- [ ] Support PyTorch via adaptateur
- [ ] Augmentation avancÃ©e (Albumentations)
- [ ] Interface de labelling interactif

### Version 1.2
- [ ] MLflow tracking optionnel
- [ ] Batch inference avec export CSV
- [ ] Calibration des modÃ¨les (ECE)
- [ ] Support modÃ¨les personnalisÃ©s

### Version 2.0
- [ ] Support multimodal (texte + images)
- [ ] AutoML et recherche d'hyperparamÃ¨tres
- [ ] DÃ©ploiement edge (TensorRT, etc.)
- [ ] Interface collaborative multi-utilisateurs

## ğŸ› ProblÃ¨mes connus

- La fonctionnalitÃ© webcam nÃ©cessite `streamlit-webrtc` (optionnel)
- Les trÃ¨s gros datasets (>10GB) peuvent nÃ©cessiter plus de RAM
- GPU requis pour les modÃ¨les ResNet sur de gros datasets

## ğŸ“„ License

MIT License - voir [LICENSE](LICENSE) pour les dÃ©tails.

## ğŸ™ Remerciements

- **Google Teachable Machine** pour l'inspiration
- **Streamlit** pour le framework UI fantastique
- **TensorFlow/Keras** pour les modÃ¨les prÃ©-entraÃ®nÃ©s
- La communautÃ© open source pour les nombreuses bibliothÃ¨ques utilisÃ©es

## ğŸ“ Support

- ğŸ› **Issues** : [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ“§ **Email** : support@teachable-machine-streamlit.com
- ğŸ’¬ **Discord** : [Serveur communautaire](https://discord.gg/teachable-machine)
- ğŸ“– **Documentation** : [Wiki dÃ©taillÃ©](https://github.com/your-repo/wiki)

---

**CrÃ©Ã© avec â¤ï¸ et Streamlit | Version 1.0.0**
